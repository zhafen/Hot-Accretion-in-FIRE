{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coolingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "import scipy.special\n",
    "import sys\n",
    "import verdict\n",
    "import os\n",
    "import tqdm\n",
    "import unyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as plt_colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.transforms\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linefinder.analyze_data.worldlines as a_worldlines\n",
    "import linefinder.analyze_data.worldline_set as worldline_set\n",
    "import linefinder.analyze_data.plot_worldlines as p_worldlines\n",
    "import linefinder.utils.presentation_constants as p_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import galaxy_dive.analyze_data.ahf as analyze_ahf\n",
    "import galaxy_dive.plot_data.ahf as plot_ahf\n",
    "import galaxy_dive.analyze_data.particle_data as particle_data\n",
    "import galaxy_dive.plot_data.generic_plotter as generic_plotter\n",
    "import galaxy_dive.plot_data.plotting as plotting\n",
    "import galaxy_dive.utils.data_operations as data_operations\n",
    "import galaxy_dive.utils.executable_helpers as exec_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linefinder.utils.file_management as file_management\n",
    "import linefinder.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = dict(\n",
    "    snum = 600,\n",
    "    tables_dir = '/work/03057/zhafen/CoolingTables/',\n",
    "    study_duplicates = False,\n",
    "    ahf_index = 600,\n",
    "    \n",
    "    # If we want to ensure some minimum number of snapshots in the galaxy after accreting\n",
    "    # (remember to account for the last 10 snapshots with small dt)\n",
    "    minInd = 0,\n",
    "    \n",
    "    # For the fancy scatter plot we're visualizing.\n",
    "    variable_alpha = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = trove.link_params_to_config(\n",
    "    '/home1/03057/zhafen/papers/Hot-Accretion-in-FIRE/analysis/hot_accretion.trove',\n",
    "    **pm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used so often it's nice to not enclose\n",
    "snum = pm['snum']\n",
    "ind = pm['ahf_index'] - snum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = a_worldlines.Worldlines(\n",
    "    tag = pm['tag'],\n",
    "    data_dir = pm['data_dir'],\n",
    "    halo_data_dir = pm['halo_data_dir'],\n",
    "    ahf_index = pm['ahf_index'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.retrieve_halo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plot_label  = r'$M_{\\rm h} = 10^{' + '{:.02g}'.format( np.log10( w.m_vir[snum] ) )\n",
    "m_plot_label += '} M_\\odot$'\n",
    "plot_label = m_plot_label + ', z={:.02}'.format( w.redshift[snum] )\n",
    "print( plot_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_list = copy.copy( p_constants.CLASSIFICATIONS_CGM_FATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_plotter = p_worldlines.WorldlinesPlotter( w, label=plot_label )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $\\theta$\n",
    "Also called $\\phi$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_momentum_fp = os.path.join( pm['processed_data_dir'], 'tot_momentums.hdf5' )\n",
    "tot_ang_momentum = verdict.Dict.from_hdf5( tot_momentum_fp )[pm['variation']]['snum{:03d}'.format( snum )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.calc_abs_phi( normal_vector=tot_ang_momentum )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mass deposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_m = w.get_data( 'M' )[:,:-1] - w.get_data( 'M' )[:,1:]\n",
    "deposited_m = np.ma.masked_array( delta_m, delta_m<0 ).sum( axis=1 ).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup axes\n",
    "t_window = 1.\n",
    "t = w.get_data( 'time' )\n",
    "x_range = [ t[ind] - t_window, t[ind] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_snaps = t[( t > x_range[0] ) & ( t < x_range[1] )][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snaps = t_snaps.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = t_snaps[1:] - t_snaps[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bins = np.zeros( ( t_snaps.size + 1, ) )\n",
    "t_bins[1:-1] = t_snaps[:-1] + dt / 2.\n",
    "t_bins[0] = t_snaps[0] - dt[0] / 2.\n",
    "t_bins[-1] = t_snaps[-1] + dt[-1] / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "\n",
    "# Median and interval stats\n",
    "logT = np.log10( w.get_selected_data( 'T', compress=False ) )#[:,ind:ind+n_snaps+1]\n",
    "R = w.get_selected_data( 'R', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "L = w.get_selected_data( 'Lmag', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "M = w.get_selected_data( 'M', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "\n",
    "logT_med = np.nanmedian( logT, axis=0 )\n",
    "R_med = np.nanmedian( R, axis=0 )\n",
    "\n",
    "logT_low = np.nanpercentile( logT, 16, axis=0 )\n",
    "logT_high = np.nanpercentile( logT, 84, axis=0 )\n",
    "\n",
    "R_low = np.nanpercentile( R, 16, axis=0 )\n",
    "R_high = np.nanpercentile( R, 84, axis=0 )\n",
    "\n",
    "inds = w.get_data( 't_1e5_inds' )\n",
    "\n",
    "R_at_Tcool = np.array( [ R[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "M_at_Tcool = np.array( [ M[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "L_at_Tcool = np.array( [ L[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "R_rgal_at_Tcool = np.array( [ R[i, ind]/w.r_gal[ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "\n",
    "t_at_Tcool = np.array( [ t[ind] for ind in inds ] )[inds >= pm['minInd']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp = os.path.join( pm['processed_data_dir'], 'summary.hdf5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = verdict.Dict.from_hdf5( data_fp )\n",
    "except OSError:\n",
    "    data = verdict.Dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R for later use\n",
    "r_vir = w.r_vir[snum]\n",
    "r_points, r_pdf = kale.density(\n",
    "    R_at_Tcool[np.invert(np.isnan(R_at_Tcool))],\n",
    "    points = np.linspace( 0., r_vir, 512 ),\n",
    "    probability = True,\n",
    "    reflect = [ 0., None ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': r_points,\n",
    "    'pdf': r_pdf,\n",
    "    'median': np.nanmedian( R_at_Tcool ),\n",
    "    '16th_percentile': np.nanpercentile( R_at_Tcool, 16 ),\n",
    "    '84th_percentile': np.nanpercentile( R_at_Tcool, 84 ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store radius for later use\n",
    "if not 'R1e5K' in data.keys():\n",
    "    data['R1e5K'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['R1e5K']:\n",
    "        data['R1e5K'][key] = {}\n",
    "    data['R1e5K'][key][pm['variation']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R for later use\n",
    "r_vir = w.r_vir[snum]\n",
    "r_points, r_pdf = kale.density(\n",
    "    R_rgal_at_Tcool[np.invert(np.isnan(R_rgal_at_Tcool))],\n",
    "    points = np.linspace( 0., r_vir / w.r_gal[0], 512 ),\n",
    "    probability = True,\n",
    "    reflect = [ 0., None ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': r_points,\n",
    "    'pdf': r_pdf,\n",
    "    'median': np.nanmedian( R_rgal_at_Tcool ),\n",
    "    '16th_percentile': np.nanpercentile( R_rgal_at_Tcool, 16 ),\n",
    "    '84th_percentile': np.nanpercentile( R_rgal_at_Tcool, 84 ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store radius relative to galaxy radius for later use\n",
    "if not 'R1e5K_rgal' in data.keys():\n",
    "    data['R1e5K_rgal'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['R1e5K_rgal']:\n",
    "        data['R1e5K_rgal'][key] = {}\n",
    "    data['R1e5K_rgal'][key][pm['variation']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store number of particles tracked\n",
    "if not 'n_tracked' in data.keys():\n",
    "    data['n_tracked'] = {}\n",
    "data['n_tracked'][pm['variation']] = w.n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf5( data_fp )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accretion Tracks and $R_{\\rm 10^5K}$ Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_before = -1.\n",
    "dt_after = 0.5\n",
    "color_dt = 0.2\n",
    "n_particles = 5\n",
    "x_lim = np.array( [ 0, 105 ] )\n",
    "y_lim = np.array( [ 5e3, 5e6 ] )\n",
    "y2_lim = np.array( [ 1, 1e2 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load sim data\n",
    "\n",
    "w.data_masker.clear_masks()\n",
    "\n",
    "# Only include particles that have never left the main galaxy\n",
    "w.data_masker.mask_data( 'n_out', -1, 1 )\n",
    "\n",
    "np.random.seed( 4 )\n",
    "\n",
    "fig = plt.figure( figsize=(12, 11), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "gs = gridspec.GridSpec(7, 1)\n",
    "gs.update( hspace=0.001 )\n",
    "\n",
    "ax1 = plt.subplot(gs[:2,0])\n",
    "\n",
    "r_for_hist = copy.copy( R_at_Tcool )\n",
    "r_for_hist[r_for_hist>x_lim[1]] = x_lim[1]*.99\n",
    "bins = np.linspace( x_lim[0], x_lim[1], 256 )\n",
    "centers = bins[:-1] + 0.5 * ( bins[1] - bins[0] )\n",
    "\n",
    "r_points, r_pdf = kale.density(\n",
    "    r_for_hist[np.invert(np.isnan(r_for_hist))],\n",
    "    points = centers,\n",
    "    probability = True,\n",
    "    reflect = [ 0., None ],\n",
    ")\n",
    "ax1.fill_between(\n",
    "    r_points,\n",
    "    r_pdf,\n",
    "    color = '0.5',\n",
    "    linewidth = 5,\n",
    ")\n",
    "\n",
    "# n, bins, patches = ax1.hist(\n",
    "#     r_for_hist,\n",
    "#     bins = ,\n",
    "#     color = '0.5',\n",
    "#     density = True,\n",
    "# )\n",
    "\n",
    "print( 'Median R_at_Tcool = {:.3g} Rvir'.format( np.nanmedian( R_at_Tcool ) / r_vir ) )\n",
    "\n",
    "# Don't do the below, because it's so far out that it's not visible\n",
    "# Create plot for volume filling distribution\n",
    "#     n_rand = int( 1e5 )\n",
    "#     data_coords = np.random.uniform( -r_vir, r_vir, (3, n_rand ) )\n",
    "#     data_r = np.sqrt( ( data_coords ** 2. ).sum( axis=0 ) )\n",
    "#     filtered_data_r = data_r[data_r<r_vir]\n",
    "#     ax1.hist(\n",
    "#         filtered_data_r,\n",
    "#         bins = bins,\n",
    "#         color = 'k',\n",
    "#         density = True,\n",
    "#         histtype = 'step',\n",
    "#         linewidth = 3,\n",
    "#         linestyle = '--',\n",
    "#     )\n",
    "\n",
    "# ax.axvline(\n",
    "#     np.median( R_at_Tcool ),\n",
    "#     color = 'k',\n",
    "# )\n",
    "\n",
    "# ax1.axvline(\n",
    "#     w.r_gal[0],\n",
    "#     color = 'k',\n",
    "#     linestyle = '--',\n",
    "#     linewidth = 3,\n",
    "# )\n",
    "\n",
    "ax1.set_xlim( x_lim )\n",
    "ax1.set_ylim( 0, r_pdf.max()*1.05 )\n",
    "\n",
    "ax1.set_xlabel( r'$R_{T=10^5{\\rm K}}$ [kpc]', fontsize=22, labelpad=10 )\n",
    "ax1.xaxis.set_label_position( 'top' )\n",
    "ax1.set_ylabel( 'PDF', fontsize=22, )\n",
    "\n",
    "ax1.tick_params( axis='x', top=True, labeltop=True, bottom=False, labelbottom=False )\n",
    "# ax1.tick_params( axis='y', left=False, labelleft=False, )\n",
    "\n",
    "ax1.annotate(\n",
    "    text='radius at which accreted gas cools\\n{}'.format( pm['variation'] ),\n",
    "    xy=(1,1),\n",
    "    xycoords='axes fraction',\n",
    "    xytext=(-10,-10),\n",
    "    textcoords='offset points',\n",
    "    ha = 'right',\n",
    "    va = 'top',\n",
    "    fontsize = 22,\n",
    ")\n",
    "\n",
    "\n",
    "### FLOW PLOT ####\n",
    "\n",
    "ax2 = plt.subplot(gs[2:,0])\n",
    "ax3 = ax\n",
    "\n",
    "# Choose particles\n",
    "particle_inds = np.random.choice( np.arange( w.n_particles ), size=n_particles, replace=False )\n",
    "\n",
    "# Get the time at the phase\n",
    "t_min_t_cool = ( t[:,np.newaxis] - t[inds] ).transpose()\n",
    "w.data['t_rel_t1e5'] = t_min_t_cool\n",
    "\n",
    "# Get positions in r-T space and color\n",
    "valid_value = ( t_min_t_cool < dt_after ) & ( t_min_t_cool > dt_before )\n",
    "valid_value = valid_value & ( w.get_data( 'n_out' ) == 0 )\n",
    "valid_value_inds = valid_value[particle_inds]\n",
    "r_vecs_all = w.get_data( 'R' )[particle_inds]\n",
    "T_vecs_all = w.get_data( 'T' )[particle_inds]\n",
    "K_vecs_all = w.get_data( 'entropy' )[particle_inds ]\n",
    "\n",
    "# Plot quivers for each particles\n",
    "for k, particle_ind in enumerate( particle_inds ):\n",
    "\n",
    "    # Format for quiver\n",
    "    r_vecs = r_vecs_all[k][valid_value_inds[k]]\n",
    "    T_vecs = np.log10( T_vecs_all[k][valid_value_inds[k]] )\n",
    "    K_vecs = np.log10( K_vecs_all[k][valid_value_inds[k]] )\n",
    "    x = r_vecs[1:]\n",
    "    y = T_vecs[1:]\n",
    "    y2 = K_vecs[1:]\n",
    "    dx = r_vecs[:-1] - r_vecs[1:]\n",
    "    dy = T_vecs[:-1] - T_vecs[1:]\n",
    "    dy2 = K_vecs[:-1] - K_vecs[1:]\n",
    "    angles_deg = np.arctan2( dy, dx ) * 180. / np.pi\n",
    "    C = t_min_t_cool[particle_inds][k,valid_value_inds[k]][1:] * 1e3\n",
    "\n",
    "    # Plot quiver\n",
    "    quiver = ax2.quiver(\n",
    "        x, y,\n",
    "        dx, dy,\n",
    "        C,\n",
    "        angles = 'xy',\n",
    "        units = 'y',\n",
    "        scale = 10,\n",
    "        minshaft = 2,\n",
    "        headwidth = 2,\n",
    "        headlength = 3.5,\n",
    "#             color = 'red',\n",
    "        cmap = palettable.scientific.diverging.Berlin_5_r.mpl_colormap,\n",
    "        norm = plt.Normalize( -color_dt*1e3, color_dt*1e3 ),\n",
    "    )\n",
    "    plotting.add_colorbar(\n",
    "        fig,\n",
    "#             ax2,\n",
    "        quiver,\n",
    "        ax_location = [0.905, 0.125, 0.03, 0.5],\n",
    "#             method = 'ax',\n",
    "    )\n",
    "\n",
    "#     w_plotter.plot_streamlines(\n",
    "#         ax = ax2,\n",
    "#         x_key = 'R',\n",
    "#         y_key = 'logT',\n",
    "#         start_ind = ind,\n",
    "#         end_ind = 'time_based',\n",
    "#         t_end = 5.,\n",
    "#         sample_inds = particle_inds,\n",
    "#         sample_selected_interval = False,\n",
    "# #         x_data_kwargs = { 'smooth_data' : True, 'smoothing_window_length' : 7 },\n",
    "# #         y_data_kwargs = { 'smooth_data' : True, 'smoothing_window_length' : 7 },\n",
    "#         color = 'black',\n",
    "#         fade_color = 'black',\n",
    "#         min_fade_linewidth = 0.5,\n",
    "#     #     fade_streamlines = False,\n",
    "#     #     line_features = gas_to_star_line_features,\n",
    "#         linewidth = 1,\n",
    "#         x_label = 'R (kpc)',\n",
    "#         y_label = 'logT (K)',\n",
    "#     #     y_scale = 'log',\n",
    "#         x_range = [ 0, 100. ],\n",
    "#         y_range = [ 3.5, 6.9 ],\n",
    "#     #     y_floor = 10.**3.8,\n",
    "#     )\n",
    "\n",
    "# Plot reference entropy lines\n",
    "r = w.get_data( 'R' )\n",
    "at_border = ( r < 1.1 * x_lim[1] ) & ( r > 0.9 * x_lim[1] ) & valid_value\n",
    "k_at_border = w.get_data( 'entropy' )[at_border]\n",
    "med_k_at_border = np.nanmedian( k_at_border )\n",
    "a_vals = [ 0, 1, 2 ]\n",
    "r_arr = np.linspace( x_lim[0], x_lim[1], 256 )\n",
    "k_arrs = [ med_k_at_border * ( r_arr / x_lim[1] )**a for a in a_vals ]\n",
    "for m, k_arr in enumerate( k_arrs ):\n",
    "    ax3.plot(\n",
    "        r_arr,\n",
    "        np.log10( k_arr ),\n",
    "        color = '0.25',\n",
    "        linewidth = 1.5,\n",
    "#             linestyle = '--',\n",
    "    )\n",
    "    ax3.annotate(\n",
    "        text = r'$\\propto r^{' + str( a_vals[m] ) + r'}$',\n",
    "        xy = ( r_arr[100], np.log10( k_arr[100] ) ),\n",
    "        xycoords = 'data',\n",
    "        xytext = ( 0, 0 ),\n",
    "        textcoords = 'offset points',\n",
    "        ha = 'right',\n",
    "        va = 'bottom',\n",
    "        fontsize = 24,\n",
    "        color = '0.25',\n",
    "    )\n",
    "\n",
    "# # Time\n",
    "# ax.plot(\n",
    "#     R_med,\n",
    "#     logT_med,\n",
    "#     linewidth = 3,\n",
    "#     color = 'b',\n",
    "# )\n",
    "# ax.fill_between(\n",
    "#     R_med,\n",
    "#     logT_low,\n",
    "#     logT_high,\n",
    "#     color = 'b',\n",
    "#     alpha = 0.25,\n",
    "# )\n",
    "\n",
    "for ax_k in [ ax2, ax3 ]:\n",
    "    ax_k.annotate(\n",
    "        text = 'accretion tracks',\n",
    "        xy=(1,0),\n",
    "        xycoords='axes fraction',\n",
    "        xytext=(-10,10),\n",
    "        textcoords='offset points',\n",
    "        ha = 'right',\n",
    "        va = 'bottom',\n",
    "        fontsize = 22,\n",
    "    )\n",
    "\n",
    "t_label = ax2.annotate(\n",
    "    text = r'$t - t_{T=10^5 {\\rm K}}$ [Myr]',\n",
    "    xy = ( 1, 0 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( 20, -30 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'center',\n",
    "    va = 'top',\n",
    "    fontsize = 24,\n",
    ")\n",
    "\n",
    "# Radius lines\n",
    "for ax_k in [ ax1, ax2, ax3 ]:\n",
    "    ax_k.axvline(\n",
    "        0.1 * r_vir,\n",
    "        color = 'k',\n",
    "        linestyle = '--',\n",
    "        linewidth = 3,\n",
    "    )\n",
    "#     ax_k.axvline(\n",
    "#         r_vir,\n",
    "#         color = 'k',\n",
    "#         linestyle = '--',\n",
    "#         linewidth = 3,\n",
    "#     )\n",
    "    ax_k.axvline(\n",
    "        w.r_gal[ind],\n",
    "        color = 'k',\n",
    "        linestyle = '--',\n",
    "        linewidth = 3,\n",
    "    )\n",
    "    if ax_k.is_first_row():\n",
    "        trans = matplotlib.transforms.blended_transform_factory( ax_k.transData, ax_k.transAxes )\n",
    "        ax_k.annotate(\n",
    "            text = r'$0.1 R_{\\rm vir}$',\n",
    "            xy = ( 0.1 * r_vir, 1.0 ),\n",
    "            xycoords = trans,\n",
    "            xytext = ( 6, -10 ),\n",
    "            textcoords = 'offset points',\n",
    "            ha = 'left',\n",
    "            va = 'top',\n",
    "            fontsize = 24,\n",
    "        )\n",
    "        ax_k.annotate(\n",
    "            text = r'$ R_{\\rm gal}$',\n",
    "            xy = ( w.r_gal[ind], 1.0 ),\n",
    "            xycoords = trans,\n",
    "            xytext = ( -6, -10 ),\n",
    "            textcoords = 'offset points',\n",
    "            ha = 'right',\n",
    "            va = 'top',\n",
    "            fontsize = 24,\n",
    "        )\n",
    "\n",
    "# Remove bottom ticks on middle axis\n",
    "#     ax2.tick_params( axis='x', bottom=False, labelbottom=False )\n",
    "\n",
    "ax2.set_xlim( x_lim )\n",
    "ax2.set_ylim( np.log10( y_lim ) )\n",
    "ax2.set_ylabel( '$\\log$T [K]', fontsize=22 )\n",
    "ax3.set_xlim( x_lim )\n",
    "ax3.set_ylim( np.log10( y2_lim) )\n",
    "ax2.set_xlabel( 'R [kpc]', fontsize=22 )\n",
    "ax3.set_ylabel( r'$\\log$K [Kev cm$^2$]', fontsize=22 )\n",
    "\n",
    "plotting.save_fig(\n",
    "    out_dir = os.path.join( pm['figure_dir'], 'tracks' ),\n",
    "    save_file = 'tracks_{}.pdf'.format( pm['variation'] ),\n",
    "    fig = fig,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace( -1., 1., 128 )\n",
    "centers = bins[:-1] + 0.5 * ( bins[1] - bins[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "# t_t1e5_centers = np.array([ -0.15, -0.06, -0.03, 0., 0.03, 0.06, 0.15, ])\n",
    "t_t1e5_centers = np.arange( -1.0, 0.5 + 0.01, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sph_harm_moment( l, m, phi, masses, radii ):\n",
    "    \n",
    "    prefactor = np.sqrt( 4. * np.pi / (2. * l + 1) )\n",
    "    ylm = scipy.special.sph_harm( m, l, 0., phi ).real\n",
    "    to_sum = masses * radii**l * ylm\n",
    "    \n",
    "    return prefactor * to_sum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time at the phase\n",
    "t_t1e5 = ( t[:,np.newaxis] - t[inds] ).transpose()\n",
    "t_t1e5_flat = t_t1e5.flatten()\n",
    "t_post_inds = np.argmin( np.abs( t_t1e5 - 0.150 ), axis=1 )\n",
    "t_pre_inds = np.argmin( np.abs( t_t1e5 + 0.150 ), axis=1 )\n",
    "insufficient_time_after = t_post_inds == 0\n",
    "insufficient_time_after_mask = np.tile( insufficient_time_after, ( w.n_snaps, 1 ) ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Data\n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "w.data_masker.mask_data( 'insufficient_time_after', custom_mask=insufficient_time_after_mask,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "phi = w.get_selected_data( 'Phi', compress=False ).flatten()\n",
    "r_scale = np.full( w.n_snaps, np.nan )\n",
    "r_scale[:w.r_gal.size] = w.r_gal\n",
    "radii = ( w.get_selected_data( 'R', compress=False ) / r_scale ).flatten()\n",
    "masses = w.get_selected_data( 'M', compress=False ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distributions\n",
    "cosphi_dists = []\n",
    "cosphi_pdfs = []\n",
    "cosphi_16ths = []\n",
    "cosphi_84ths = []\n",
    "cosphi_stds = []\n",
    "q20 = []\n",
    "q33 = []\n",
    "for i, center in enumerate( tqdm.tqdm( t_t1e5_centers ) ):\n",
    "    bin_low = center - dt / 2.\n",
    "    bin_high = center + dt / 2.\n",
    "    in_bin = ( t_t1e5_flat > bin_low ) & ( t_t1e5_flat < bin_high )\n",
    "    \n",
    "    phi_arr = phi[in_bin]\n",
    "    phi_arr_rad = phi_arr * np.pi / 180.\n",
    "    cosphi_arr = np.cos( phi_arr_rad )\n",
    "    cosphi_points, cosphi_pdf = kale.density(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        points = centers,\n",
    "        probability = True,\n",
    "        reflect = [ -1., 1. ],\n",
    "    )\n",
    "    cosphi_hist, cosphi_bins = np.histogram(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        bins = bins,\n",
    "        density = True,\n",
    "    )\n",
    "    cosphi_pdfs.append( cosphi_pdf )\n",
    "    cosphi_dists.append( cosphi_hist )\n",
    "    \n",
    "    cosphi_arr_comp = cosphi_arr.compressed()\n",
    "    cosphi_16ths.append( np.nanpercentile( cosphi_arr_comp, 16 ) )\n",
    "    cosphi_84ths.append( np.nanpercentile( cosphi_arr_comp, 84. ) )\n",
    "    cosphi_stds.append( np.nanstd( cosphi_arr_comp ) )\n",
    "    \n",
    "    masked = np.invert( radii.mask ) & in_bin\n",
    "    q20_i = calc_sph_harm_moment(\n",
    "        2,\n",
    "        0,\n",
    "        phi[masked].compressed(),\n",
    "        masses[masked].compressed(),\n",
    "        radii[masked].compressed()\n",
    "    )\n",
    "    q20.append( q20_i )\n",
    "    q33_i = calc_sph_harm_moment(\n",
    "        3,\n",
    "        3,\n",
    "        phi[masked].compressed(),\n",
    "        masses[masked].compressed(),\n",
    "        radii[masked].compressed()\n",
    "    )\n",
    "    q33.append( q33_i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_is = np.arange( 118, 122 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10, 4.5 ), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "z_max = t_t1e5_centers.max()\n",
    "z_min = t_t1e5_centers.min()\n",
    "        \n",
    "for i, cosphi_dist in enumerate( cosphi_dists ):\n",
    "\n",
    "    z_width = z_max - z_min\n",
    "    color_value = ( t_t1e5_centers[i] - z_min )/z_width\n",
    "    color = palettable.scientific.diverging.Roma_3.mpl_colormap( color_value )\n",
    "\n",
    "    if i in labeled_is:\n",
    "        if np.isclose( t_t1e5_centers[i], 0. ):\n",
    "            t_t1e5_centers[i] = 0\n",
    "        label = (\n",
    "            '{:.3g}'.format( t_t1e5_centers[i]*1e3 ) +\n",
    "            r' Myr'\n",
    "        )\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    line = ax.plot(\n",
    "        centers,\n",
    "        cosphi_dist, #/ (np.pi / 180. / 2. * np.sin( bin_centers * np.pi/180. ) ),\n",
    "        linewidth = 1.5,\n",
    "        color = color,\n",
    "        label = label,\n",
    "#             zorder = 10 - i,\n",
    "    )\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'x',\n",
    "    top = True,\n",
    "    labeltop = ax.is_first_row(),\n",
    "    bottom = ax.is_last_row(),\n",
    "    labelbottom = ax.is_last_row(),\n",
    ")\n",
    "\n",
    "ax.axhline(\n",
    "    0.5,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "ax.axvline(\n",
    "    0,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "\n",
    "# Sim name label\n",
    "ax.annotate(\n",
    "    text = pm['variation'],\n",
    "    xy = ( 0, 1 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( 20, -20 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 26,\n",
    ")\n",
    "\n",
    "# line labels\n",
    "ax.annotate(\n",
    "    text = 'spherical\\ndistribution',\n",
    "    xy = ( -1, 0.5 ),\n",
    "    xycoords = 'data',\n",
    "    xytext = ( 10, 10 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'bottom',\n",
    "    fontsize = 22,\n",
    ")\n",
    "ax.annotate(\n",
    "    text = 'disc\\ndistribution',\n",
    "    xy = ( 0, 3.75 ),\n",
    "    xycoords = 'data',\n",
    "    xytext = ( 15, -10 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 22,\n",
    ")\n",
    "\n",
    "t_label = ax.annotate(\n",
    "    text = r'$t - t_{T=10^5 {\\rm K}}$',\n",
    "    xy = ( 1, 0.875 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( -25, 0 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'right',\n",
    "    va = 'bottom',\n",
    "    fontsize = 24,\n",
    ")\n",
    "t_label.set_zorder( 1000 )\n",
    "ax.legend(\n",
    "    prop={'size': 17},\n",
    "    loc = 'center right',\n",
    ")\n",
    "\n",
    "ax.set_xlim( -1, 1 )\n",
    "ax.set_ylim( 0, 3.75 )\n",
    "\n",
    "ax.set_xlabel( r'$\\cos\\ \\theta$', fontsize=22 )\n",
    "# if ax.is_first_row():\n",
    "#     ax.xaxis.set_label_position( 'top' )\n",
    "ax.set_ylabel( r'PDF$\\ (\\cos\\ \\theta$)', fontsize=22 )\n",
    "\n",
    "plotting.save_fig(\n",
    "    out_dir = os.path.join( pm['figure_dir'], 'ang_dist_evolution' ),\n",
    "    save_file = 'theta_vs_t_{}.pdf'.format( pm['variation'] ),\n",
    "    fig = fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ind = np.argmin( np.abs( centers ) )\n",
    "pdf_at_zero = np.array( cosphi_dists )[:,zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': centers,\n",
    "    't_t1e5_centers': t_t1e5_centers,\n",
    "    'pdf': np.array( cosphi_pdfs ),\n",
    "    'hist': np.array( cosphi_dists ),\n",
    "    '16th_percentile': cosphi_16ths,\n",
    "    '84th_percentile': cosphi_84ths,\n",
    "    'std': cosphi_stds,\n",
    "    'pdf(cos theta=0)': pdf_at_zero,\n",
    "    'q20': q20,\n",
    "    'q33': q33,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store circularity for later use\n",
    "if not 'cosphi' in data.keys():\n",
    "    data['cosphi'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['cosphi']:\n",
    "        data['cosphi'][key] = {}\n",
    "    data['cosphi'][key][pm['variation']] = item\n",
    "data.to_hdf5( data_fp )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Distribution for Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "t_t1e5_centers = np.arange( -1.0, 0.5 + 0.01, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Data\n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "w.data_masker.mask_data( 'insufficient_time_after', custom_mask=insufficient_time_after_mask,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angular momentum\n",
    "ang_mom_dir = tot_ang_momentum / np.linalg.norm( tot_ang_momentum )\n",
    "j = w.get_selected_data( 'L', )\n",
    "jz = np.dot( j.transpose(), ang_mom_dir )\n",
    "jmag = w.get_selected_data( 'Lmag', )\n",
    "jz_jmag = ( jz / jmag )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "phi = np.arccos( jz_jmag ) * 180. / np.pi\n",
    "r_scale = np.full( w.n_snaps, np.nan )\n",
    "r_scale[:w.r_gal.size] = w.r_gal\n",
    "radii = ( w.get_selected_data( 'R', compress=False ) / r_scale ).compressed()\n",
    "masses = w.get_selected_data( 'M', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get masking t_t1e5\n",
    "t_t1e5_flat = t_t1e5[np.invert( w.data_masker.get_mask() )].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distributions\n",
    "cosphi_dists = []\n",
    "cosphi_pdfs = []\n",
    "cosphi_16ths = []\n",
    "cosphi_84ths = []\n",
    "cosphi_stds = []\n",
    "for i, center in enumerate( tqdm.tqdm( t_t1e5_centers ) ):\n",
    "    bin_low = center - dt / 2.\n",
    "    bin_high = center + dt / 2.\n",
    "    in_bin = ( t_t1e5_flat > bin_low ) & ( t_t1e5_flat < bin_high )\n",
    "    \n",
    "    if in_bin.sum() == 0:\n",
    "        cosphi_pdfs.append( np.zeros( centers.shape ) )\n",
    "        cosphi_dists.append( np.zeros( centers.shape ) )\n",
    "        cosphi_16ths.append( np.nan )\n",
    "        cosphi_84ths.append( np.nan )\n",
    "        cosphi_stds.append( np.nan )\n",
    "        continue\n",
    "    \n",
    "    phi_arr = phi[in_bin]\n",
    "    phi_arr_rad = phi_arr * np.pi / 180.\n",
    "    cosphi_arr = np.cos( phi_arr_rad )\n",
    "    cosphi_points, cosphi_pdf = kale.density(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        points = centers,\n",
    "        probability = True,\n",
    "        reflect = [ -1., 1. ],\n",
    "    )\n",
    "    cosphi_hist, cosphi_bins = np.histogram(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        bins = bins,\n",
    "        density = True,\n",
    "    )\n",
    "    cosphi_pdfs.append( cosphi_pdf )\n",
    "    cosphi_dists.append( cosphi_hist )\n",
    "    \n",
    "    cosphi_16ths.append( np.nanpercentile( cosphi_arr, 16 ) )\n",
    "    cosphi_84ths.append( np.nanpercentile( cosphi_arr, 84. ) )\n",
    "    cosphi_stds.append( np.nanstd( cosphi_arr ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_is = []\n",
    "for i in range( len( cosphi_dists ) ):\n",
    "    if i % 20 == 0:\n",
    "        labeled_is.append( i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10, 4.5 ), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "# z_max = t_t1e5_centers.max()\n",
    "z_min = -0.5\n",
    "z_max = -z_min\n",
    "        \n",
    "for i, cosphi_dist in enumerate( cosphi_dists ):\n",
    "\n",
    "    z_width = z_max - z_min\n",
    "    color_value = ( t_t1e5_centers[i] - z_min )/z_width\n",
    "    color = palettable.scientific.diverging.Roma_3.mpl_colormap( color_value )\n",
    "    \n",
    "    if ( t_t1e5_centers[i] < -0.5 ) or ( t_t1e5_centers[i] > 0.50 ):\n",
    "        continue\n",
    "        \n",
    "    if i in labeled_is:\n",
    "        if np.isclose( t_t1e5_centers[i], 0. ):\n",
    "            t_t1e5_centers[i] = 0\n",
    "        label = (\n",
    "            '{:.3g}'.format( t_t1e5_centers[i]*1e3 ) +\n",
    "            r' Myr'\n",
    "        )\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    cosphi_dist = np.cumsum( cosphi_dist )\n",
    "    cosphi_dist /= cosphi_dist[-1]\n",
    "    line = ax.plot(\n",
    "        centers,\n",
    "        cosphi_dist, #/ (np.pi / 180. / 2. * np.sin( bin_centers * np.pi/180. ) ),\n",
    "        linewidth = 5,\n",
    "        color = color,\n",
    "        label = label,\n",
    "#             zorder = 10 - i,\n",
    "    )\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'x',\n",
    "    top = True,\n",
    "    labeltop = ax.is_first_row(),\n",
    "    bottom = ax.is_last_row(),\n",
    "    labelbottom = ax.is_last_row(),\n",
    ")\n",
    "\n",
    "ax.axhline(\n",
    "    0.5,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "ax.axvline(\n",
    "    0,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "\n",
    "# Sim name label\n",
    "ax.annotate(\n",
    "    text = pm['variation'],\n",
    "    xy = ( 0, 1 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( 20, -20 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 26,\n",
    ")\n",
    "\n",
    "# line labels\n",
    "# ax.annotate(\n",
    "#     text = 'spherical\\ndistribution',\n",
    "#     xy = ( -1, 0.5 ),\n",
    "#     xycoords = 'data',\n",
    "#     xytext = ( 10, 10 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'left',\n",
    "#     va = 'bottom',\n",
    "#     fontsize = 22,\n",
    "# )\n",
    "# ax.annotate(\n",
    "#     text = 'disc\\ndistribution',\n",
    "#     xy = ( 0, 3.75 ),\n",
    "#     xycoords = 'data',\n",
    "#     xytext = ( 15, -10 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'left',\n",
    "#     va = 'top',\n",
    "#     fontsize = 22,\n",
    "# )\n",
    "\n",
    "t_label = ax.annotate(\n",
    "    text = r'$t - t_{T=10^5 {\\rm K}}$',\n",
    "    xy = ( 1, 0.875 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( -25, 0 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'right',\n",
    "    va = 'bottom',\n",
    "    fontsize = 24,\n",
    ")\n",
    "t_label.set_zorder( 1000 )\n",
    "ax.legend(\n",
    "    prop={'size': 17},\n",
    "    bbox_to_anchor = [ 0.5, 1. ],\n",
    "    loc = 'upper right',\n",
    ")\n",
    "\n",
    "# ax.set_xlim( -1, 1 )\n",
    "ax.set_xlim( 0.5, 1 )\n",
    "ax.set_ylim( 0, 1 )\n",
    "# ax.set_ylim( 0.01, 45 )\n",
    "# ax.set_yscale( 'log' )\n",
    "\n",
    "ax.set_xlabel( r'$\\cos\\ \\theta$', fontsize=22 )\n",
    "# if ax.is_first_row():\n",
    "#     ax.xaxis.set_label_position( 'top' )\n",
    "ax.set_ylabel( r'PDF$\\ (\\cos\\ \\theta$)', fontsize=22 )\n",
    "\n",
    "plotting.save_fig(\n",
    "    out_dir = os.path.join( pm['figure_dir'], 'ang_dist_evolution' ),\n",
    "    save_file = 'jzjmag_vs_t_{}.pdf'.format( pm['variation'] ),\n",
    "    fig = fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ind = np.argmin( np.abs( centers ) )\n",
    "pdf_at_zero = np.array( cosphi_dists )[:,zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': centers,\n",
    "    't_t1e5_centers': t_t1e5_centers,\n",
    "    'pdf': np.array( cosphi_pdfs ),\n",
    "    'hist': np.array( cosphi_dists ),\n",
    "    '16th_percentile': cosphi_16ths,\n",
    "    '84th_percentile': cosphi_84ths,\n",
    "    'std': cosphi_stds,\n",
    "    'pdf(cos theta=0)': pdf_at_zero,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store circularity for later use\n",
    "if not 'jzjmag' in data.keys():\n",
    "    data['jzjmag'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['jzjmag']:\n",
    "        data['jzjmag'][key] = {}\n",
    "    data['jzjmag'][key][pm['variation']] = item\n",
    "data.to_hdf5( data_fp )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "\n",
    "    # Mask Data\n",
    "    w.data_masker.clear_masks()\n",
    "    w.data_masker.mask_data( 'n_out', -1, 1 ) # Only include particles that have never left the main galaxy\n",
    "    w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "    w.data_masker.mask_data( 'insufficient_time_after', custom_mask=insufficient_time_after_mask,  )\n",
    "\n",
    "    pre = {}\n",
    "    for key in [ 'Rx', 'Ry', 'Rz', 'M', 'Den', 'T' ]:\n",
    "        pre[key] = w.get_selected_data( key, compress=False )[np.arange(w.n_particles),t_pre_inds].compressed()\n",
    "\n",
    "    den_msunkpc3 = ( pre['Den']*unyt.mp/unyt.cm**3  ).to( 'Msun/kpc**3' )\n",
    "    pre['Vol'] = pre['M'] * unyt.Msun / den_msunkpc3\n",
    "    pre['h'] = ( 3. * pre['Vol'] / 4. / np.pi )**(1./3.)\n",
    "\n",
    "    post = {}\n",
    "    for key in [ 'Rx', 'Ry', 'Rz', 'M', 'Den', 'T' ]:\n",
    "        post[key] = w.get_selected_data( key, compress=False )[np.arange(w.n_particles),t_post_inds].compressed()\n",
    "\n",
    "    den_msunkpc3 = ( post['Den']*unyt.mp/unyt.cm**3  ).to( 'Msun/kpc**3' )\n",
    "    post['Vol'] = post['M'] * unyt.Msun / den_msunkpc3\n",
    "    post['h'] = ( 3. * post['Vol'] / 4. / np.pi )**(1./3.)\n",
    "\n",
    "    prepost_labels = [\n",
    "        '150 Myrs before cooling',\n",
    "        '150 Myrs after cooling',\n",
    "    ]\n",
    "    prepost_filetags = [\n",
    "        'before',\n",
    "        'after',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = palettable.scientific.diverging.Berlin_3.mpl_colormap\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'berlin_white',\n",
    "    [\n",
    "        palettable.scientific.diverging.Berlin_3.mpl_colors[0],\n",
    "        'w',\n",
    "        palettable.scientific.diverging.Berlin_3.mpl_colors[-1],\n",
    "    ],\n",
    ")\n",
    "norm = plt_colors.LogNorm( vmin=1e4, vmax=1e6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "    for i, d in enumerate( [ pre, post ] ):\n",
    "\n",
    "        fig = plt.figure( figsize=(12,10), facecolor='k' )\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Point size\n",
    "        lim = 0.13 * w.r_vir[snum]\n",
    "        width_in_data = 2 * lim\n",
    "        width_in_pixels = ax.get_window_extent().width\n",
    "        pixels_to_points = fig.dpi / 72.\n",
    "        scale = 10.\n",
    "        radius = d['h'] * ( width_in_pixels / width_in_data ) * pixels_to_points * scale\n",
    "        s = ( radius )**2.\n",
    "\n",
    "        # Colors\n",
    "        colors = cmap( norm( d['T'] ) )\n",
    "\n",
    "        # Alpha\n",
    "        if pm['variable_alpha']:\n",
    "            column_den = d['M'] / d['h']**2.\n",
    "            alpha = plt_colors.LogNorm( vmin=np.nanmin( column_den ), vmax=np.nanmax( column_den ) )( column_den ) * 0.065 * ( 50000 / w.n_particles)\n",
    "            alpha[alpha>1.] = 1.\n",
    "            alpha[alpha<0.] = 0.\n",
    "            colors[:,3] = alpha\n",
    "        else:\n",
    "            colors[:,3] = 0.01\n",
    "\n",
    "        # Plot itself\n",
    "        ax.scatter(\n",
    "            d['Rx'],\n",
    "            d['Rz'],\n",
    "            s = s,\n",
    "            c = colors,\n",
    "            edgecolors = 'none',\n",
    "        )\n",
    "\n",
    "        # Scale bar\n",
    "        size = min( 30., 0.95 * lim )\n",
    "        xy = ( -size, -0.95*lim )\n",
    "        ax.plot(\n",
    "            xy[0] + np.array([ 0., size ]),\n",
    "            [ xy[1], xy[1] ],\n",
    "            linewidth = 10,\n",
    "            color = 'w',\n",
    "        )\n",
    "        ax.annotate(\n",
    "            text = '{:.2g} kpc'.format( size ),\n",
    "            xy = xy,\n",
    "            xycoords = 'data',\n",
    "            xytext = ( 5, 10 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'left',\n",
    "            color = 'w',\n",
    "            fontsize = 42,\n",
    "        )\n",
    "\n",
    "        # Plot label\n",
    "        ax.annotate(\n",
    "            text = prepost_labels[i],\n",
    "            xy = ( 1, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( -10, -10 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'right',\n",
    "            color = 'w',\n",
    "            fontsize = 42,\n",
    "        )\n",
    "\n",
    "        # Limits\n",
    "        ax.set_xlim( -lim, lim )\n",
    "        ax.set_ylim( -lim, lim )\n",
    "        ax.set_aspect( 'equal' )\n",
    "\n",
    "        # Ticks\n",
    "        plt.tick_params(\n",
    "            which = 'both',\n",
    "            left = False,\n",
    "            labelleft = False,\n",
    "            bottom = False,\n",
    "            labelbottom = False,\n",
    "        )\n",
    "\n",
    "        # Change colors\n",
    "        ax.set_facecolor( 'k' )\n",
    "        plt.setp( ax.spines.values(), color='w' )\n",
    "        [i.set_linewidth(3) for i in ax.spines.values()]\n",
    "\n",
    "        plotting.save_fig(\n",
    "            out_dir = os.path.join( pm['figure_dir'], 'projected' ),\n",
    "            save_file = '{}_{}.png'.format( prepost_filetags[i], pm['variation'] ),\n",
    "            fig = fig,\n",
    "            resolution = 150.,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "    # Setup time steps\n",
    "    delta_t = 0.01\n",
    "    t_movie_after = np.arange( 0., 0.5 + delta_t, delta_t )\n",
    "    t_movie_before = -1. * np.arange( 0., 1.5 + delta_t, delta_t )[1:][::-1]\n",
    "    t_movie = np.concatenate( [ t_movie_before, t_movie_after ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Time Offset\n",
    "Find offset for each worldline (to account for t_t1e5 occuring between snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "\n",
    "    # Mask Data\n",
    "    w.data_masker.clear_masks()\n",
    "    w.data_masker.mask_data( 'n_out', -1, 1 ) # Only include particles that have never left the main galaxy\n",
    "    w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "\n",
    "    # Find particles that are valid near t1e5\n",
    "    mask_overall = w.data_masker.get_mask()\n",
    "    mask_at_t1e5 = mask_overall[np.arange(w.n_particles),inds]\n",
    "    mask_after_t1e5 = mask_overall[np.arange(w.n_particles),inds-1]\n",
    "    masked_near_t1e5 = np.logical_and( mask_at_t1e5, mask_after_t1e5 )\n",
    "    valid_near_t1e5 = np.invert( masked_near_t1e5 )\n",
    "\n",
    "    # Find the temperatures to interpolate to get the offset\n",
    "    T_at_t1e5 = w.get_data( 'T' )[np.arange(w.n_particles),inds][valid_near_t1e5]\n",
    "    T_after_t1e5 = w.get_data( 'T' )[np.arange(w.n_particles),inds-1][valid_near_t1e5]\n",
    "    logT_interp = np.log10( np.array([ T_at_t1e5, T_after_t1e5 ]).transpose() )\n",
    "\n",
    "    # Find the times to interpolate to get the offset\n",
    "    t_t1e5_at_t1e5 = w.get_data( 't_t_1e5', )[np.arange(w.n_particles),inds][valid_near_t1e5]\n",
    "    t_t1e5_after_t1e5 = w.get_data( 't_t_1e5', )[np.arange(w.n_particles),inds-1][valid_near_t1e5]\n",
    "    t_t1e5_interp = np.array([ t_t1e5_at_t1e5, t_t1e5_after_t1e5 ]).transpose()\n",
    "\n",
    "    # Get the offset\n",
    "    time_offsets = []\n",
    "    n_wrong = 0\n",
    "    for i, t_1e5_interp_i in enumerate( tqdm.tqdm( t_t1e5_interp ) ):\n",
    "        interp_fn = scipy.interpolate.interp1d( logT_interp[i], t_t1e5_interp[i],  )\n",
    "        try:\n",
    "            time_offsets.append( interp_fn( 5. ) )\n",
    "        except ValueError:\n",
    "            time_offsets.append( np.nan )\n",
    "            n_wrong += 1\n",
    "\n",
    "    time_offsets = np.array( time_offsets )\n",
    "    print( n_wrong, n_wrong / t_t1e5_interp.shape[0] )\n",
    "\n",
    "    time_offsets_all = np.full( w.n_particles, np.nan )\n",
    "    time_offsets_all[valid_near_t1e5] = time_offsets\n",
    "\n",
    "    t_t1e5_corrected = t_t1e5 - time_offsets_all[:,np.newaxis]\n",
    "\n",
    "    # The below code shows individual cases where t_1e5 appears to be calculated wrong\n",
    "    if np.isnan( time_offsets ).sum() > 0:\n",
    "        i = np.argmax( time_offsets )\n",
    "        weird_original_ind = np.arange( w.n_particles )[valid_near_t1e5][i]\n",
    "        print( np.log10( w.get_data( 'T' )[weird_original_ind] )[inds[weird_original_ind]-2:inds[weird_original_ind]+1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "\n",
    "    ds = []\n",
    "    for i, t_frame in enumerate( tqdm.tqdm( t_movie ) ):\n",
    "\n",
    "        t_frame_inds = np.argmin( np.abs( t_t1e5_corrected - t_frame ), axis=1 )\n",
    "\n",
    "        # Prepare to mask\n",
    "        if len( w.data_masker.masks ) == 3:\n",
    "            del w.data_masker.masks[2]\n",
    "\n",
    "        # Mask data that's out of bounds\n",
    "        out_of_bounds = t_frame_inds == 0\n",
    "        out_of_bounds_mask = np.tile( out_of_bounds, ( w.n_snaps, 1 ) ).transpose()\n",
    "        w.data_masker.mask_data( 'out_of_bounds', custom_mask=out_of_bounds_mask,  )\n",
    "\n",
    "        # Base parameters\n",
    "        d = {}\n",
    "        for key in [ 'Rx', 'Ry', 'Rz', 'M', 'Den', 'T' ]:\n",
    "            d[key] = w.get_selected_data( key, compress=False )[np.arange(w.n_particles),t_frame_inds].compressed()\n",
    "\n",
    "        # Volume and smoothing length\n",
    "        den_msunkpc3 = ( d['Den']*unyt.mp/unyt.cm**3  ).to( 'Msun/kpc**3' )\n",
    "        d['Vol'] = d['M'] * unyt.Msun / den_msunkpc3\n",
    "        d['h'] = ( 3. * d['Vol'] / 4. / np.pi )**(1./3.)\n",
    "\n",
    "        ds.append( d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This more-complicated data retrieval interpolates for each step, and is probably not necessary.\n",
    "\n",
    "# ds = []\n",
    "# for i, t_frame in enumerate( tqdm.tqdm( t_movie ) ):\n",
    "    \n",
    "#     # DEBUG\n",
    "#     if i > 0:\n",
    "#         continue\n",
    "    \n",
    "#     t_frame_inds = np.argmin( np.abs( t_t1e5 - t_frame ), axis=1 )\n",
    "#     t_frame_inds_next = np.argmin( np.abs( t_t1e5 - t_movie[i+1] ), axis=1 )\n",
    "    \n",
    "#     # Prepare to mask\n",
    "#     if len( w.data_masker.masks ) == 3:\n",
    "#         del w.data_masker.masks[2]\n",
    "    \n",
    "#     # Mask data that's out of bounds\n",
    "#     out_of_bounds = t_frame_inds_next == 0\n",
    "#     out_of_bounds_mask = np.tile( out_of_bounds, ( w.n_snaps, 1 ) ).transpose()\n",
    "#     w.data_masker.mask_data( 'out_of_bounds', custom_mask=out_of_bounds_mask,  )\n",
    "\n",
    "#     # Get the full mask\n",
    "#     mask = w.data_masker.get_mask()\n",
    "#     mask_current = mask[np.arange(w.n_particles),t_frame_inds]\n",
    "#     mask_next = mask[np.arange(w.n_particles),t_frame_inds_next]\n",
    "#     mask = np.logical_and( mask_current, mask_next, masked_near_t1e5 )\n",
    "#     valid = np.invert( mask )\n",
    "    \n",
    "#     # Find the times for interpolation\n",
    "#     t_t_1e5_frames = np.array([\n",
    "#         w.get_data( 't_t_1e5' )[np.arange(w.n_particles),t_frame_inds][valid],\n",
    "#         w.get_data( 't_t_1e5' )[np.arange(w.n_particles),t_frame_inds_next][valid]\n",
    "#     ]).transpose()\n",
    "#     time_offsets_frames = time_offsets_all[valid]\n",
    "#     interp_times = t_t_1e5_frames[:,0] + time_offsets_frames\n",
    "    \n",
    "#     # Base parameters\n",
    "#     d = {}\n",
    "#     for key in [ 'Rx', 'Ry', 'Rz', 'M', 'Den', 'T' ]:\n",
    "#         data_frames = np.array([\n",
    "#             w.get_data( key )[np.arange(w.n_particles),t_frame_inds][valid],\n",
    "#             w.get_data( key )[np.arange(w.n_particles),t_frame_inds_next][valid]\n",
    "#         ]).transpose()\n",
    "        \n",
    "#         # Transform some into log\n",
    "#         if key in [ 'Den', 'T' ]:\n",
    "#             data_frames = np.log10( data_frames )\n",
    "            \n",
    "#         # Get interpolated value\n",
    "#         data_interpd = []\n",
    "#         for j, t_1e5_interp_j in enumerate( t_t_1e5_frames ):\n",
    "#             interp_fn = scipy.interpolate.interp1d( t_1e5_interp_j, data_frames[j],  )\n",
    "#             data_interpd.append( interp_fn( interp_times[j] ) )\n",
    "#         data_interpd = np.array( data_interpd )\n",
    "        \n",
    "#         if key in [ 'Den', 'T' ]:\n",
    "#             data_interpd = 10.**data_interpd\n",
    "            \n",
    "#         d[key] = data_interpd\n",
    "        \n",
    "#     # Volume and smoothing length\n",
    "#     den_msunkpc3 = ( d['Den']*unyt.mp/unyt.cm**3  ).to( 'Msun/kpc**3' )\n",
    "#     d['Vol'] = d['M'] * unyt.Msun / den_msunkpc3\n",
    "#     d['h'] = ( 3. * d['Vol'] / 4. / np.pi )**(1./3.)\n",
    "\n",
    "#     ds.append( d )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['generate_expensive_visualizations']:\n",
    "\n",
    "    # Frame and scalebar size objects\n",
    "    def round_down(num, divisor):\n",
    "        return num - (num%divisor)\n",
    "    # The t_movie cut is set to be useless by default.\n",
    "    lim = np.max( [ np.nanpercentile( np.abs( ds[i]['Rx'] ), 95 ) for i in np.arange(len(ds))[t_movie >= -0.5] ] )\n",
    "\n",
    "    i_focused = 0\n",
    "\n",
    "    for i, d in enumerate( tqdm.tqdm( ds ) ):\n",
    "\n",
    "        fig = plt.figure( figsize=(12,10), facecolor='k' )\n",
    "        ax = plt.gca()\n",
    "\n",
    "        # Point size\n",
    "        width_in_data = 2 * lim\n",
    "        width_in_pixels = ax.get_window_extent().width\n",
    "        pixels_to_points = fig.dpi / 72.\n",
    "        scale = 10.\n",
    "        radius = d['h'] * ( width_in_pixels / width_in_data ) * pixels_to_points * scale\n",
    "        s = ( radius )**2.\n",
    "\n",
    "        # Colors\n",
    "        colors = cmap( norm( d['T'] ) )\n",
    "\n",
    "        # Alpha\n",
    "        if pm['variable_alpha']:\n",
    "            column_den = d['M'] / d['h']**2.\n",
    "            alpha = plt_colors.LogNorm( vmin=np.nanmin( column_den ), vmax=np.nanmax( column_den ) )( column_den ) * 0.065 * ( 50000 / w.n_particles)\n",
    "            alpha[alpha>1.] = 1.\n",
    "            alpha[alpha<0.] = 0.\n",
    "            colors[:,3] = alpha\n",
    "        else:\n",
    "            colors[:,3] = 0.01\n",
    "\n",
    "        # Plot itself\n",
    "        ax.scatter(\n",
    "            d['Rx'],\n",
    "            d['Rz'],\n",
    "            s = s,\n",
    "            c = colors,\n",
    "            edgecolors = 'none',\n",
    "        )\n",
    "\n",
    "        # Scale bar\n",
    "        size = round_down( min( 30., 0.95 * lim ), 10 )\n",
    "        if np.isclose( size, 0. ):\n",
    "            size = 10.\n",
    "        xy = ( -size, -0.95*lim )\n",
    "        ax.plot(\n",
    "            xy[0] + np.array([ 0., size ]),\n",
    "            [ xy[1], xy[1] ],\n",
    "            linewidth = 10,\n",
    "            color = 'w',\n",
    "        )\n",
    "        ax.annotate(\n",
    "            text = '{:.2g} kpc'.format( size ),\n",
    "            xy = xy,\n",
    "            xycoords = 'data',\n",
    "            xytext = ( 5, 10 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'bottom',\n",
    "            ha = 'left',\n",
    "            color = 'w',\n",
    "            fontsize = 42,\n",
    "        )\n",
    "\n",
    "        # Plot label\n",
    "        ax.annotate(\n",
    "            text = r'$t - t_{T = 10^5 {\\rm K}} =$' + '{} Myrs'.format( int( t_movie[i]*1e3 ) ),\n",
    "            xy = ( 1, 1 ),\n",
    "            xycoords = 'axes fraction',\n",
    "            xytext = ( -10, -10 ),\n",
    "            textcoords = 'offset points',\n",
    "            va = 'top',\n",
    "            ha = 'right',\n",
    "            color = 'w',\n",
    "            fontsize = 42,\n",
    "        )\n",
    "\n",
    "        # Limits\n",
    "        ax.set_xlim( -lim, lim )\n",
    "        ax.set_ylim( -lim, lim )\n",
    "        ax.set_aspect( 'equal' )\n",
    "\n",
    "        # Ticks\n",
    "        plt.tick_params(\n",
    "            which = 'both',\n",
    "            left = False,\n",
    "            labelleft = False,\n",
    "            bottom = False,\n",
    "            labelbottom = False,\n",
    "        )\n",
    "\n",
    "        # Change colors\n",
    "        ax.set_facecolor( 'k' )\n",
    "        plt.setp( ax.spines.values(), color='w' )\n",
    "        [m.set_linewidth(3) for m in ax.spines.values()]\n",
    "\n",
    "        plotting.save_fig(\n",
    "            out_dir = os.path.join( pm['data_dir'], 'projected_frames' ),\n",
    "            save_file = '{}_{:0>3d}.png'.format( pm['variation'], i ),\n",
    "            fig = fig,\n",
    "            resolution = 150.,\n",
    "        )\n",
    "\n",
    "        # Save movie focused on time of cooling\n",
    "        if np.abs( t_movie[i] ) <= 0.150:\n",
    "            plotting.save_fig(\n",
    "                out_dir = os.path.join( pm['data_dir'], 'projected_frames' ),\n",
    "                save_file = '{}_focused_{:0>3d}.png'.format( pm['variation'], i_focused ),\n",
    "                fig = fig,\n",
    "                resolution = 150.,\n",
    "            )\n",
    "            i_focused += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = pm['variation']\n",
    "disk_fracs = []\n",
    "for i, pdf in enumerate( cosphi_dists ):\n",
    "\n",
    "    in_disk = np.abs( data['cosphi']['points'][key] ) < pm['disk_costheta']\n",
    "    disk_fracs.append( pdf[in_disk].sum()/pdf.sum() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
