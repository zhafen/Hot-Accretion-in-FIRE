{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coolingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "import scipy.special\n",
    "import sys\n",
    "import verdict\n",
    "import os\n",
    "import tqdm\n",
    "import unyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kalepy as kale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as plt_colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.transforms\n",
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linefinder.analyze_data.worldlines as a_worldlines\n",
    "import linefinder.analyze_data.worldline_set as worldline_set\n",
    "import linefinder.analyze_data.plot_worldlines as p_worldlines\n",
    "import linefinder.utils.presentation_constants as p_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import galaxy_dive.analyze_data.ahf as analyze_ahf\n",
    "import galaxy_dive.plot_data.ahf as plot_ahf\n",
    "import galaxy_dive.analyze_data.particle_data as particle_data\n",
    "import galaxy_dive.plot_data.generic_plotter as generic_plotter\n",
    "import galaxy_dive.plot_data.plotting as plotting\n",
    "import galaxy_dive.utils.data_operations as data_operations\n",
    "import galaxy_dive.utils.executable_helpers as exec_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linefinder.utils.file_management as file_management\n",
    "import linefinder.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = dict(\n",
    "    snum = 600,\n",
    "    tables_dir = '/work/03057/zhafen/CoolingTables/',\n",
    "    study_duplicates = False,\n",
    "    ahf_index = 600,\n",
    "    \n",
    "#     # If we want to ensure some minimum number of snapshots in the galaxy after accreting\n",
    "#     # (remember to account for the last 10 snapshots with small dt)\n",
    "#     minInd = 0,\n",
    "#     maxInd = 54, # Corresponds to 1 Gyr. We don't look at accretion prior.\n",
    "    \n",
    "    # For the fancy scatter plot we're visualizing.\n",
    "    variable_alpha = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = trove.link_params_to_config(\n",
    "    '/home1/03057/zhafen/papers/Hot-Accretion-in-FIRE/analysis/hot_accretion.trove',\n",
    "    script_id = 'nb.10',\n",
    "    **pm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used so often it's nice to not enclose\n",
    "snum = pm['snum']\n",
    "ind = pm['ahf_index'] - snum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = a_worldlines.Worldlines(\n",
    "    tag = pm['tag'],\n",
    "    data_dir = pm['base_data_dir'],\n",
    "    halo_data_dir = pm['halo_data_dir'],\n",
    "    ahf_index = pm['ahf_index'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.retrieve_halo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plot_label  = r'$M_{\\rm h} = 10^{' + '{:.02g}'.format( np.log10( w.m_vir[snum] ) )\n",
    "m_plot_label += '} M_\\odot$'\n",
    "plot_label = m_plot_label + ', z={:.02}'.format( w.redshift[snum] )\n",
    "print( plot_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_list = copy.copy( p_constants.CLASSIFICATIONS_CGM_FATE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_plotter = p_worldlines.WorldlinesPlotter( w, label=plot_label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_processed_data_dir = pm['config_parser'].get( 'DEFAULT', 'processed_data_dir' )\n",
    "default_data_fp = os.path.join( base_processed_data_dir, 'summary.hdf5' )\n",
    "default_data = verdict.Dict.from_hdf5( default_data_fp, create_nonexistent=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp = os.path.join( pm['processed_data_dir'], 'summary.hdf5' )\n",
    "data = verdict.Dict.from_hdf5( data_fp, create_nonexistent=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tchange_key = pm['central_indices'].split( '_' )[0]\n",
    "t_tchange_key = 't_' + tchange_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tchange_label = helpers.get_t_tchange_label( pm )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $\\theta$\n",
    "Also called $\\phi$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_momentum_fp = os.path.join( base_processed_data_dir, 'tot_momentums.hdf5' )\n",
    "tot_ang_momentum = verdict.Dict.from_hdf5( tot_momentum_fp )[pm['variation']]['snum{:03d}'.format( snum )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.total_ang_momentum = tot_ang_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.calc_abs_phi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $\\vec j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_mom = w.get_data( 'J' )\n",
    "w.data['Jmag'] = w.get_data( 'Jmag' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_ang_momentum_normed = tot_ang_momentum / np.linalg.norm( tot_ang_momentum )\n",
    "w.data['Jz'] = np.array([ np.dot( specific_mom[:,:,i].transpose(), tot_ang_momentum_normed ) for i in range( w.snums.size ) ]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.data['Jz/J'] = w.data['Jz'] / w.data['Jmag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate central indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pm['central_indices'] == 'tcools_inds':\n",
    "    inds = w.calc_tcools_inds(\n",
    "        lookback_time_max = pm['lookback_time_max'],\n",
    "        choose_first = pm['choose_first'],\n",
    "        B = pm['logTcools'],\n",
    "    )\n",
    "else:\n",
    "    calc_fn = getattr( w, 'calc_{}'.format( pm['central_indices'] ) )\n",
    "    inds = calc_fn(\n",
    "        lookback_time_max = pm['lookback_time_max'],\n",
    "        choose_first = pm['choose_first'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup axes\n",
    "t_window = 1.\n",
    "t = w.get_data( 'time' )\n",
    "x_range = [ t[ind] - t_window, t[ind] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_snaps = t[( t > x_range[0] ) & ( t < x_range[1] )][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_snaps = t_snaps.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = t_snaps[1:] - t_snaps[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bins = np.zeros( ( t_snaps.size + 1, ) )\n",
    "t_bins[1:-1] = t_snaps[:-1] + dt / 2.\n",
    "t_bins[0] = t_snaps[0] - dt[0] / 2.\n",
    "t_bins[-1] = t_snaps[-1] + dt[-1] / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "\n",
    "# Median and interval stats\n",
    "logT = np.log10( w.get_selected_data( 'T', compress=False ) )#[:,ind:ind+n_snaps+1]\n",
    "R = w.get_selected_data( 'R', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "L = w.get_selected_data( 'Lmag', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "M = w.get_selected_data( 'M', compress=False )#[:,ind:ind+n_snaps+1]\n",
    "\n",
    "logT_med = np.nanmedian( logT, axis=0 )\n",
    "R_med = np.nanmedian( R, axis=0 )\n",
    "\n",
    "logT_low = np.nanpercentile( logT, 16, axis=0 )\n",
    "logT_high = np.nanpercentile( logT, 84, axis=0 )\n",
    "\n",
    "R_low = np.nanpercentile( R, 16, axis=0 )\n",
    "R_high = np.nanpercentile( R, 84, axis=0 )\n",
    "\n",
    "inds = w.get_data( pm['central_indices'] )\n",
    "particle_inds = np.arange( inds.size )\n",
    "\n",
    "valid = ( inds >= pm['minInd'] ) & ( inds < pm['maxInd'] )\n",
    "R_at_tchange = R[particle_inds[valid],inds[valid]]\n",
    "M_at_tchange = M[particle_inds[valid],inds[valid]]\n",
    "L_at_tchange = R[particle_inds[valid],inds[valid]]\n",
    "R_rgal_at_tchange = R[particle_inds[valid],inds[valid]] / w.r_gal[inds[valid]]\n",
    "t_at_tchange = t[inds[valid]]\n",
    "\n",
    "# R_at_tchange = np.array( [ R[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "# M_at_tchange = np.array( [ M[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "# L_at_tchange = np.array( [ L[i, ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "# R_rgal_at_tchange = np.array( [ R[i, ind]/w.r_gal[ind] for i, ind in enumerate( inds ) ] )[inds >= pm['minInd']]\n",
    "\n",
    "# t_at_tchange = np.array( [ t[ind] for ind in inds ] )[inds >= pm['minInd']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R for later use\n",
    "r_vir = w.r_vir[snum]\n",
    "r_points, r_pdf = kale.density(\n",
    "    R_at_tchange[np.invert(np.isnan(R_at_tchange))],\n",
    "    points = np.linspace( 0., r_vir, 512 ),\n",
    "    probability = True,\n",
    "    reflect = [ 0., None ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': r_points,\n",
    "    'pdf': r_pdf,\n",
    "    'median': np.nanmedian( R_at_tchange ),\n",
    "    '16th_percentile': np.nanpercentile( R_at_tchange, 16 ),\n",
    "    '84th_percentile': np.nanpercentile( R_at_tchange, 84 ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store radius for later use\n",
    "flag = pm['central_indices'].split( '_' )[0][1:]\n",
    "r_key = 'R' + flag\n",
    "if not r_key in data.keys():\n",
    "    data[r_key] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data[r_key]:\n",
    "        data[r_key][key] = {}\n",
    "    data[r_key][key][pm['variation']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store R for later use\n",
    "r_vir = w.r_vir[snum]\n",
    "r_points, r_pdf = kale.density(\n",
    "    R_rgal_at_tchange[np.invert(np.isnan(R_rgal_at_tchange))],\n",
    "    points = np.linspace( 0., r_vir / w.r_gal[0], 512 ),\n",
    "    probability = True,\n",
    "    reflect = [ 0., None ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': r_points,\n",
    "    'pdf': r_pdf,\n",
    "    'median': np.nanmedian( R_rgal_at_tchange ),\n",
    "    '16th_percentile': np.nanpercentile( R_rgal_at_tchange, 16 ),\n",
    "    '84th_percentile': np.nanpercentile( R_rgal_at_tchange, 84 ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store radius relative to galaxy radius for later use\n",
    "rrgal_key = r_key + '_rgal'\n",
    "if not rrgal_key in data.keys():\n",
    "    data[rrgal_key] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data[rrgal_key]:\n",
    "        data[rrgal_key][key] = {}\n",
    "    data[rrgal_key][key][pm['variation']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store number of particles tracked\n",
    "if not 'n_tracked' in data.keys():\n",
    "    data['n_tracked'] = {}\n",
    "data['n_tracked'][pm['variation']] = w.n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf5( data_fp, handle_jagged_arrs='row datasets' )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace( -1., 1., 128 )\n",
    "centers = bins[:-1] + 0.5 * ( bins[1] - bins[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "t_tchange_centers = np.arange( -1.0, 0.5 + 0.01, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sph_harm_moment( l, m, phi, masses, radii ):\n",
    "    \n",
    "    prefactor = np.sqrt( 4. * np.pi / (2. * l + 1) )\n",
    "    ylm = scipy.special.sph_harm( m, l, 0., phi ).real\n",
    "    to_sum = masses * radii**l * ylm\n",
    "    \n",
    "    return prefactor * to_sum.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the time at the phase\n",
    "t_tchange = w.get_data( t_tchange_key )\n",
    "t_tchange_flat = t_tchange.flatten()\n",
    "t_post_inds = np.argmin( np.abs( t_tchange - 0.150 ), axis=1 )\n",
    "t_pre_inds = np.argmin( np.abs( t_tchange + 0.150 ), axis=1 )\n",
    "insufficient_time_after = t_post_inds == 0\n",
    "insufficient_time_after_mask = np.tile( insufficient_time_after, ( w.n_snaps, 1 ) ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Data\n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "w.data_masker.mask_data( 'insufficient_time_after', custom_mask=insufficient_time_after_mask,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "phi = w.get_selected_data( 'Phi', compress=False ).flatten()\n",
    "r_scale = np.full( w.n_snaps, np.nan )\n",
    "r_scale[:w.r_gal.size] = w.r_gal\n",
    "radii = ( w.get_selected_data( 'R', compress=False ) / r_scale ).flatten()\n",
    "masses = w.get_selected_data( 'M', compress=False ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distributions\n",
    "cosphi_dists = []\n",
    "cosphi_pdfs = []\n",
    "cosphi_16ths = []\n",
    "cosphi_84ths = []\n",
    "cosphi_stds = []\n",
    "q20 = []\n",
    "q33 = []\n",
    "for i, center in enumerate( tqdm.tqdm( t_tchange_centers ) ):\n",
    "    bin_low = center - dt / 2.\n",
    "    bin_high = center + dt / 2.\n",
    "    in_bin = ( t_tchange_flat > bin_low ) & ( t_tchange_flat < bin_high )\n",
    "    \n",
    "    phi_arr = phi[in_bin]\n",
    "    phi_arr_rad = phi_arr * np.pi / 180.\n",
    "    cosphi_arr = np.cos( phi_arr_rad )\n",
    "    cosphi_points, cosphi_pdf = kale.density(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        points = centers,\n",
    "        probability = True,\n",
    "        reflect = [ -1., 1. ],\n",
    "    )\n",
    "    cosphi_hist, cosphi_bins = np.histogram(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        bins = bins,\n",
    "        density = True,\n",
    "    )\n",
    "    cosphi_pdfs.append( cosphi_pdf )\n",
    "    cosphi_dists.append( cosphi_hist )\n",
    "    \n",
    "    cosphi_arr_comp = cosphi_arr.compressed()\n",
    "    cosphi_16ths.append( np.nanpercentile( cosphi_arr_comp, 16 ) )\n",
    "    cosphi_84ths.append( np.nanpercentile( cosphi_arr_comp, 84. ) )\n",
    "    cosphi_stds.append( np.nanstd( cosphi_arr_comp ) )\n",
    "    \n",
    "    masked = np.invert( radii.mask ) & in_bin\n",
    "    q20_i = calc_sph_harm_moment(\n",
    "        2,\n",
    "        0,\n",
    "        phi[masked].compressed(),\n",
    "        masses[masked].compressed(),\n",
    "        radii[masked].compressed()\n",
    "    )\n",
    "    q20.append( q20_i )\n",
    "    q33_i = calc_sph_harm_moment(\n",
    "        3,\n",
    "        3,\n",
    "        phi[masked].compressed(),\n",
    "        masses[masked].compressed(),\n",
    "        radii[masked].compressed()\n",
    "    )\n",
    "    q33.append( q33_i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_is = np.arange( 0, 150, 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10, 4.5 ), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "z_max = t_tchange_centers.max()\n",
    "z_min = t_tchange_centers.min()\n",
    "        \n",
    "for i, cosphi_dist in enumerate( cosphi_dists ):\n",
    "\n",
    "    z_width = z_max - z_min\n",
    "    color_value = ( t_tchange_centers[i] - z_min )/z_width\n",
    "    color = palettable.scientific.diverging.Roma_3.mpl_colormap( color_value )\n",
    "\n",
    "    if i in labeled_is:\n",
    "        if np.isclose( t_tchange_centers[i], 0. ):\n",
    "            t_tchange_centers[i] = 0\n",
    "        label = (\n",
    "            '{:.3g}'.format( t_tchange_centers[i]*1e3 ) +\n",
    "            r' Myr'\n",
    "        )\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    line = ax.plot(\n",
    "        centers,\n",
    "        cosphi_dist, #/ (np.pi / 180. / 2. * np.sin( bin_centers * np.pi/180. ) ),\n",
    "        linewidth = 1.5,\n",
    "        color = color,\n",
    "        label = label,\n",
    "#             zorder = 10 - i,\n",
    "    )\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'x',\n",
    "    top = True,\n",
    "    labeltop = ax.is_first_row(),\n",
    "    bottom = ax.is_last_row(),\n",
    "    labelbottom = ax.is_last_row(),\n",
    ")\n",
    "\n",
    "ax.axhline(\n",
    "    0.5,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "ax.axvline(\n",
    "    0,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "\n",
    "# Sim name label\n",
    "ax.annotate(\n",
    "    text = pm['variation'],\n",
    "    xy = ( 0, 1 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( 20, -20 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 26,\n",
    ")\n",
    "\n",
    "# line labels\n",
    "ax.annotate(\n",
    "    text = 'spherical\\ndistribution',\n",
    "    xy = ( -1, 0.5 ),\n",
    "    xycoords = 'data',\n",
    "    xytext = ( 10, 10 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'bottom',\n",
    "    fontsize = 22,\n",
    ")\n",
    "ax.annotate(\n",
    "    text = 'disc\\ndistribution',\n",
    "    xy = ( 0, 3.75 ),\n",
    "    xycoords = 'data',\n",
    "    xytext = ( 15, -10 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 22,\n",
    ")\n",
    "\n",
    "t_label = ax.annotate(\n",
    "    text = t_tchange_label,\n",
    "    xy = ( 1, 0.875 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( -25, 0 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'right',\n",
    "    va = 'bottom',\n",
    "    fontsize = 24,\n",
    ")\n",
    "t_label.set_zorder( 1000 )\n",
    "ax.legend(\n",
    "    prop={'size': 17},\n",
    "    loc = 'center right',\n",
    ")\n",
    "\n",
    "ax.set_xlim( -1, 1 )\n",
    "ax.set_ylim( 0, 3.75 )\n",
    "\n",
    "ax.set_xlabel( r'$\\cos\\ \\theta$', fontsize=22 )\n",
    "# if ax.is_first_row():\n",
    "#     ax.xaxis.set_label_position( 'top' )\n",
    "ax.set_ylabel( r'PDF$\\ (\\cos\\ \\theta$)', fontsize=22 )\n",
    "\n",
    "plotting.save_fig(\n",
    "    out_dir = os.path.join( pm['figure_dir'], 'ang_dist_evolution' ),\n",
    "    save_file = 'theta_vs_t_{}.pdf'.format( pm['variation'] ),\n",
    "    fig = fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ind = np.argmin( np.abs( centers ) )\n",
    "pdf_at_zero = np.array( cosphi_dists )[:,zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': centers,\n",
    "    't_tchange_centers': t_tchange_centers,\n",
    "    'pdf': np.array( cosphi_pdfs ),\n",
    "    'hist': np.array( cosphi_dists ),\n",
    "    '16th_percentile': cosphi_16ths,\n",
    "    '84th_percentile': cosphi_84ths,\n",
    "    'std': cosphi_stds,\n",
    "    'pdf(cos theta=0)': pdf_at_zero,\n",
    "    'q20': q20,\n",
    "    'q33': q33,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store circularity for later use\n",
    "if not 'cosphi' in data.keys():\n",
    "    data['cosphi'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['cosphi']:\n",
    "        data['cosphi'][key] = {}\n",
    "    data['cosphi'][key][pm['variation']] = item\n",
    "data.to_hdf5( data_fp, handle_jagged_arrs='row datasets' )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Distribution for Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "t_tchange_centers = np.arange( -1.0, 0.5 + 0.01, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Data\n",
    "w.data_masker.clear_masks()\n",
    "w.data_masker.mask_data( 'PType', data_value=0 )\n",
    "w.data_masker.mask_data( 'insufficient_time_after', custom_mask=insufficient_time_after_mask,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angular momentum\n",
    "ang_mom_dir = tot_ang_momentum / np.linalg.norm( tot_ang_momentum )\n",
    "j = w.get_selected_data( 'L', )\n",
    "jz = np.dot( j.transpose(), ang_mom_dir )\n",
    "jmag = w.get_selected_data( 'Lmag', )\n",
    "jz_jmag = ( jz / jmag )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "phi = np.arccos( jz_jmag ) * 180. / np.pi\n",
    "r_scale = np.full( w.n_snaps, np.nan )\n",
    "r_scale[:w.r_gal.size] = w.r_gal\n",
    "radii = ( w.get_selected_data( 'R', compress=False ) / r_scale ).compressed()\n",
    "masses = w.get_selected_data( 'M', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get masking t_tchange\n",
    "t_tchange_flat = t_tchange[np.invert( w.data_masker.get_mask() )].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distributions\n",
    "cosphi_dists = []\n",
    "cosphi_pdfs = []\n",
    "cosphi_16ths = []\n",
    "cosphi_84ths = []\n",
    "cosphi_stds = []\n",
    "for i, center in enumerate( tqdm.tqdm( t_tchange_centers ) ):\n",
    "    bin_low = center - dt / 2.\n",
    "    bin_high = center + dt / 2.\n",
    "    in_bin = ( t_tchange_flat > bin_low ) & ( t_tchange_flat < bin_high )\n",
    "    \n",
    "    if in_bin.sum() == 0:\n",
    "        cosphi_pdfs.append( np.zeros( centers.shape ) )\n",
    "        cosphi_dists.append( np.zeros( centers.shape ) )\n",
    "        cosphi_16ths.append( np.nan )\n",
    "        cosphi_84ths.append( np.nan )\n",
    "        cosphi_stds.append( np.nan )\n",
    "        continue\n",
    "    \n",
    "    phi_arr = phi[in_bin]\n",
    "    phi_arr_rad = phi_arr * np.pi / 180.\n",
    "    cosphi_arr = np.cos( phi_arr_rad )\n",
    "    cosphi_points, cosphi_pdf = kale.density(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        points = centers,\n",
    "        probability = True,\n",
    "        reflect = [ -1., 1. ],\n",
    "    )\n",
    "    cosphi_hist, cosphi_bins = np.histogram(\n",
    "        cosphi_arr[np.invert(np.isnan(cosphi_arr))],\n",
    "        bins = bins,\n",
    "        density = True,\n",
    "    )\n",
    "    cosphi_pdfs.append( cosphi_pdf )\n",
    "    cosphi_dists.append( cosphi_hist )\n",
    "    \n",
    "    cosphi_16ths.append( np.nanpercentile( cosphi_arr, 16 ) )\n",
    "    cosphi_84ths.append( np.nanpercentile( cosphi_arr, 84. ) )\n",
    "    cosphi_stds.append( np.nanstd( cosphi_arr ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_is = []\n",
    "for i in range( len( cosphi_dists ) ):\n",
    "    if i % 20 == 0:\n",
    "        labeled_is.append( i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(10, 4.5 ), facecolor='w' )\n",
    "ax = plt.gca()\n",
    "\n",
    "# z_max = t_tchange_centers.max()\n",
    "z_min = -0.5\n",
    "z_max = -z_min\n",
    "        \n",
    "for i, cosphi_dist in enumerate( cosphi_dists ):\n",
    "\n",
    "    z_width = z_max - z_min\n",
    "    color_value = ( t_tchange_centers[i] - z_min )/z_width\n",
    "    color = palettable.scientific.diverging.Roma_3.mpl_colormap( color_value )\n",
    "    \n",
    "    if ( t_tchange_centers[i] < -0.5 ) or ( t_tchange_centers[i] > 0.50 ):\n",
    "        continue\n",
    "        \n",
    "    if i in labeled_is:\n",
    "        if np.isclose( t_tchange_centers[i], 0. ):\n",
    "            t_tchange_centers[i] = 0\n",
    "        label = (\n",
    "            '{:.3g}'.format( t_tchange_centers[i]*1e3 ) +\n",
    "            r' Myr'\n",
    "        )\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    cosphi_dist = np.cumsum( cosphi_dist )\n",
    "    cosphi_dist /= cosphi_dist[-1]\n",
    "    line = ax.plot(\n",
    "        centers,\n",
    "        cosphi_dist, #/ (np.pi / 180. / 2. * np.sin( bin_centers * np.pi/180. ) ),\n",
    "        linewidth = 5,\n",
    "        color = color,\n",
    "        label = label,\n",
    "#             zorder = 10 - i,\n",
    "    )\n",
    "\n",
    "ax.tick_params(\n",
    "    axis = 'x',\n",
    "    top = True,\n",
    "    labeltop = ax.is_first_row(),\n",
    "    bottom = ax.is_last_row(),\n",
    "    labelbottom = ax.is_last_row(),\n",
    ")\n",
    "\n",
    "ax.axhline(\n",
    "    0.5,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "ax.axvline(\n",
    "    0,\n",
    "    color = '.2',\n",
    "    linestyle = '-',\n",
    "    linewidth = 2,\n",
    ")\n",
    "\n",
    "# Sim name label\n",
    "ax.annotate(\n",
    "    text = pm['variation'],\n",
    "    xy = ( 0, 1 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( 20, -20 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'left',\n",
    "    va = 'top',\n",
    "    fontsize = 26,\n",
    ")\n",
    "\n",
    "# line labels\n",
    "# ax.annotate(\n",
    "#     text = 'spherical\\ndistribution',\n",
    "#     xy = ( -1, 0.5 ),\n",
    "#     xycoords = 'data',\n",
    "#     xytext = ( 10, 10 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'left',\n",
    "#     va = 'bottom',\n",
    "#     fontsize = 22,\n",
    "# )\n",
    "# ax.annotate(\n",
    "#     text = 'disc\\ndistribution',\n",
    "#     xy = ( 0, 3.75 ),\n",
    "#     xycoords = 'data',\n",
    "#     xytext = ( 15, -10 ),\n",
    "#     textcoords = 'offset points',\n",
    "#     ha = 'left',\n",
    "#     va = 'top',\n",
    "#     fontsize = 22,\n",
    "# )\n",
    "\n",
    "t_label = ax.annotate(\n",
    "    text = t_tchange_label,\n",
    "    xy = ( 1, 0.875 ),\n",
    "    xycoords = 'axes fraction',\n",
    "    xytext = ( -25, 0 ),\n",
    "    textcoords = 'offset points',\n",
    "    ha = 'right',\n",
    "    va = 'bottom',\n",
    "    fontsize = 24,\n",
    ")\n",
    "t_label.set_zorder( 1000 )\n",
    "ax.legend(\n",
    "    prop={'size': 17},\n",
    "    bbox_to_anchor = [ 0.5, 1. ],\n",
    "    loc = 'upper right',\n",
    ")\n",
    "\n",
    "# ax.set_xlim( -1, 1 )\n",
    "ax.set_xlim( 0.5, 1 )\n",
    "ax.set_ylim( 0, 1 )\n",
    "# ax.set_ylim( 0.01, 45 )\n",
    "# ax.set_yscale( 'log' )\n",
    "\n",
    "ax.set_xlabel( r'$\\cos\\ \\theta$', fontsize=22 )\n",
    "# if ax.is_first_row():\n",
    "#     ax.xaxis.set_label_position( 'top' )\n",
    "ax.set_ylabel( r'PDF$\\ (\\cos\\ \\theta$)', fontsize=22 )\n",
    "\n",
    "plotting.save_fig(\n",
    "    out_dir = os.path.join( pm['figure_dir'], 'ang_dist_evolution' ),\n",
    "    save_file = 'jzjmag_vs_t_{}.pdf'.format( pm['variation'] ),\n",
    "    fig = fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_ind = np.argmin( np.abs( centers ) )\n",
    "pdf_at_zero = np.array( cosphi_dists )[:,zero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_store = {\n",
    "    'points': centers,\n",
    "    't_tchange_centers': t_tchange_centers,\n",
    "    'pdf': np.array( cosphi_pdfs ),\n",
    "    'hist': np.array( cosphi_dists ),\n",
    "    '16th_percentile': cosphi_16ths,\n",
    "    '84th_percentile': cosphi_84ths,\n",
    "    'std': cosphi_stds,\n",
    "    'pdf(cos theta=0)': pdf_at_zero,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store circularity for later use\n",
    "if not 'jzjmag' in data.keys():\n",
    "    data['jzjmag'] = {}\n",
    "for key, item in data_to_store.items():\n",
    "    if key not in data['jzjmag']:\n",
    "        data['jzjmag'][key] = {}\n",
    "    data['jzjmag'][key][pm['variation']] = item\n",
    "data.to_hdf5( data_fp, handle_jagged_arrs='row datasets' )\n",
    "print( 'Stored summary data at {}'.format( data_fp ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
